# algo param
algo_name: ddpg
gamma: 0.99  # discount factor
rho: .005  # target network update rate
expl_std: 0.1  # std of Gaussian for exploration
batch_size: 256  # batch size for both actor and critic
start_timesteps: 25000  # time steps initial random policy is used
eval_freq: 5000  # how often (time steps) we evaluate
max_timesteps: 1000_000  # max time steps to run environment
buffer_size: 1000_000  # replay buffer size
norm_state: false

# network param
actor_hidden_size: [256, 256]
critic_hidden_size: [256, 256]
actor_lr: !!float 3e-4
critic_lr: !!float 3e-4

# env param
env_name: HalfCheetah-v3
device: "cuda"