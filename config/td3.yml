# algo param
algo_name: td3
gamma: 0.99  # discount factor
buffer_size: 1000_000
batch_size: 256
eval_freq: 5000
rho: .005  # target network update rate
c: 0.5  # noise clip threshold for target policy
sigma: 0.2  # std of Gaussian for target actor
expl_std: 0.1  # std of Gaussian for exploration
start_timesteps: 25000  # time steps initial random policy is used
policy_delay: 2  # frequency of delayed policy updates
max_timesteps: 1000_000
norm_state: false

# net param
actor_hidden_size: [256, 256]
critic_hidden_size: [256, 256]
actor_lr: !!float 3e-4
critic_lr: !!float 3e-4

# others
seed: 0
device: cuda:0