# algo param
algo_name: sac
rho: .005  # target network update rate
env_steps: 1  # update model after every env_steps
start_timesteps: 10_000  # time steps initial random policy is used
gamma: 0.99  # discount factor
buffer_size: 1000_000
max_timesteps: 1000_000
batch_size: 256
eval_freq: 5000
fixed_alpha: false  # whether to fine-tune alpha
alpha: 1.0
alpha_lr: !!float 3e-4
norm_state: false
load_model: false

# env param
actor_hidden_size: [256, 256]
critic_hidden_size: [256, 256]
actor_lr: !!float 3e-4
critic_lr: !!float 3e-4

# others
seed: 0
device: cuda:0
